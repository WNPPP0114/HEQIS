# æ–‡ä»¶å: deploy_export.py (Windowsè¿è¡Œ - ç»ˆææ‰¹å¤„ç†ç‰ˆ)

import torch
import sys
import os
import joblib
import json
import numpy as np
import pandas as pd
import glob
import re
import time

# å¼•å…¥é¡¹ç›®æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
import models
# å¼•å…¥å®éªŒé…ç½®ä»¥è·å–æ¨¡å‹ç»“æ„å‚æ•°
from experiment_runner import COMMON_ARGS

# --- è·¯å¾„é…ç½® ---
BASE_OUTPUT_DIR = 'output/multi_gan'  # è®­ç»ƒæƒé‡å­˜æ”¾åœ°
FILTERED_OUTPUT_DIR = 'output_filtered_signals'  # æœ€ä½³ç­–ç•¥ç»“æœå­˜æ”¾åœ°
DATA_BASE_DIR = 'csv_data/predict'  # Scalerå­˜æ”¾åœ°
EXPORT_DIR = 'deploy_output'  # å¯¼å‡ºæ–‡ä»¶çš„å­˜æ”¾ç›®å½•


def get_available_stocks():
    """æ‰«æ output_filtered_signals ç›®å½•è·å–æœ‰æœ€ä½³ç­–ç•¥çš„è‚¡ç¥¨åˆ—è¡¨"""
    stocks = []
    # æŸ¥æ‰¾æ‰€æœ‰å­˜åœ¨ best_metrics.csv çš„ç›®å½•
    pattern = os.path.join(FILTERED_OUTPUT_DIR, '*', '*', 'best_metrics.csv')
    files = glob.glob(pattern)

    for f in files:
        parts = f.replace('\\', '/').split('/')
        if len(parts) >= 4:
            sector = parts[-3]
            stock = parts[-2]
            stocks.append({'sector': sector, 'name': stock, 'metrics_path': f})

    # æŒ‰æ¿å—å’Œåç§°æ’åºï¼Œä¿è¯åˆ—è¡¨é¡ºåºå›ºå®š
    stocks.sort(key=lambda x: (x['sector'], x['name']))
    return stocks


def find_matching_generator_index(metrics_path):
    """
    é€šè¿‡æ¯”å¯¹ best_metrics.csv ä¸åŒç›®å½•ä¸‹å…¶ä»– G*_metrics.csv çš„å†…å®¹ï¼Œ
    åå‘æ¨å¯¼ generator_indexã€‚
    """
    folder_path = os.path.dirname(metrics_path)

    try:
        # 1. è¯»å–æœ€ä½³æ–‡ä»¶çš„å…³é”®æŒ‡æ ‡
        df_best = pd.read_csv(metrics_path)
        if df_best.empty: return None
        if 'generator_index' in df_best.columns: return int(df_best.iloc[0]['generator_index'])

        target_return = df_best.iloc[0]['cumulative_return_percentage']
        target_trades = df_best.iloc[0]['num_trades']

        # 2. æ‰«æåŒç›®å½•ä¸‹çš„åŸå§‹ G æ–‡ä»¶
        g_files = glob.glob(os.path.join(folder_path, 'G*_metrics.csv'))

        for g_file in g_files:
            if 'best_metrics.csv' in g_file: continue
            try:
                df_curr = pd.read_csv(g_file)
                if df_curr.empty: continue
                curr_return = df_curr.iloc[0]['cumulative_return_percentage']
                curr_trades = df_curr.iloc[0]['num_trades']

                if np.isclose(target_return, curr_return, atol=1e-5) and target_trades == curr_trades:
                    filename = os.path.basename(g_file)
                    match = re.search(r'G(\d+)_', filename)
                    if match: return int(match.group(1))
            except Exception:
                continue
        return None
    except Exception:
        return None


def get_model_config(gen_idx):
    """æ ¹æ®ç”Ÿæˆå™¨ç´¢å¼• (1-based) ä» COMMON_ARGS è·å–æ¨¡å‹é…ç½®"""
    list_idx = gen_idx - 1
    if list_idx >= len(COMMON_ARGS['generators']):
        raise ValueError(f"ç”Ÿæˆå™¨ç´¢å¼• G{gen_idx} è¶…å‡ºäº†é…ç½®åˆ—è¡¨èŒƒå›´ï¼")

    return {
        'model_type': COMMON_ARGS['generators'][list_idx],
        'window_size': COMMON_ARGS['window_sizes'][list_idx],
        'use_rope': COMMON_ARGS['use_rope'][list_idx]
    }


def get_model_class(model_type):
    name_map = {
        'gru': models.Generator_gru, 'lstm': models.Generator_lstm,
        'transformer': models.Generator_transformer, 'transformer_deep': models.Generator_transformer_deep,
        'rnn': models.Generator_rnn, 'dct': models.Generator_dct,
        'mpd': models.Generator_mpd, 'bigru': models.Generator_bigru,
        'bilstm': models.Generator_bilstm
    }
    return name_map.get(model_type.lower())


def export_stock(stock_info, quiet=False):
    """
    æ‰§è¡Œå¯¼å‡ºé€»è¾‘
    :param quiet: å¦‚æœä¸ºTrueï¼Œå‡å°‘éƒ¨åˆ†æ‰“å°ï¼Œé€‚åˆæ‰¹é‡æ¨¡å¼
    :return: (success: bool, message: str)
    """
    sector = stock_info['sector']
    stock_name = stock_info['name']

    if not quiet:
        print(f"\n{'=' * 20} æ­£åœ¨å¯¼å‡º: {stock_name} ({sector}) {'=' * 20}")

    # 1. ç¡®å®šæœ€ä½³ç­–ç•¥
    gen_idx = find_matching_generator_index(stock_info['metrics_path'])
    if gen_idx is None:
        return False, "æ— æ³•åŒ¹é…æœ€ä½³ç­–ç•¥ç´¢å¼•"

    # 2. è·å–æ¨¡å‹é…ç½®
    try:
        config = get_model_config(gen_idx)
    except Exception as e:
        return False, f"é…ç½®åŒ¹é…å¤±è´¥: {e}"

    if not quiet:
        print(f"ğŸ¯ ç­–ç•¥é”å®š: G{gen_idx} | æ¨¡å‹: {config['model_type']} | çª—å£: {config['window_size']}")

    # 3. å®šä½æ–‡ä»¶è·¯å¾„
    ckpt_dir = os.path.join(BASE_OUTPUT_DIR, sector, stock_name, 'ckpt', 'generators')
    ckpt_filename = f"{gen_idx}_{config['model_type']}.pt"
    ckpt_path = os.path.join(ckpt_dir, ckpt_filename)

    scaler_dir = os.path.join(DATA_BASE_DIR, sector, stock_name)
    x_scaler_path = os.path.join(scaler_dir, 'x_scaler.gz')
    y_scaler_path = os.path.join(scaler_dir, 'y_scaler.gz')

    if not os.path.exists(ckpt_path):
        # å°è¯•æ¨¡ç³ŠåŒ¹é…
        possible = glob.glob(os.path.join(ckpt_dir, f"{gen_idx}_*.pt"))
        if possible:
            ckpt_path = possible[0]
        else:
            return False, f"æƒé‡æ–‡ä»¶ç¼ºå¤±: {ckpt_filename}"

    if not os.path.exists(x_scaler_path):
        return False, "Scaleræ–‡ä»¶ç¼ºå¤±"

    # 4. åŠ è½½ Scaler
    try:
        x_scaler = joblib.load(x_scaler_path)
        y_scaler = joblib.load(y_scaler_path)
        input_size = x_scaler.n_features_in_
    except Exception as e:
        return False, f"ScaleråŠ è½½é”™è¯¯: {e}"

    # 5. åˆå§‹åŒ–æ¨¡å‹
    ModelClass = get_model_class(config['model_type'])
    if not ModelClass: return False, f"æœªçŸ¥æ¨¡å‹ç±»å‹: {config['model_type']}"

    init_kwargs = {'use_rope': config['use_rope']}
    if config['model_type'] == 'mpd':
        init_kwargs.update({'input_height': config['window_size'], 'input_width': input_size, 'num_classes': 3,
                            'pretrainer_type': 'cae'})
    elif config['model_type'] in ['transformer', 'transformer_deep', 'dct']:
        init_kwargs.update({'input_dim': input_size, 'output_len': 1})
    else:
        init_kwargs.update({'input_size': input_size, 'out_size': 1})

    try:
        model = ModelClass(**init_kwargs)
        state_dict = torch.load(ckpt_path, map_location='cpu')
        model.load_state_dict(state_dict, strict=False)
        model.eval()
    except Exception as e:
        return False, f"æ¨¡å‹åŠ è½½æƒé‡å¤±è´¥: {e}"

    # 6. å¯¼å‡º
    save_dir = os.path.join(EXPORT_DIR, sector, stock_name)
    os.makedirs(save_dir, exist_ok=True)
    onnx_path = os.path.join(save_dir, 'model_deploy.onnx')
    json_path = os.path.join(save_dir, 'scaler_params.json')

    # å¯¼å‡ºJSON
    params = {
        "stock_name": stock_name,
        "model_type": config['model_type'],
        "best_generator_index": gen_idx,
        "x_scale": x_scaler.scale_.tolist(),
        "x_min": x_scaler.min_.tolist(),
        "y_scale": y_scaler.scale_.tolist(),
        "y_min": y_scaler.min_.tolist(),
        "n_features": input_size,
        "window_size": config['window_size']
    }
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(params, f, indent=4, ensure_ascii=False)

    # å¯¼å‡ºONNX
    if config['model_type'] == 'mpd':
        dummy_input = torch.randn(1, 1, config['window_size'], input_size)
    else:
        dummy_input = torch.randn(1, config['window_size'], input_size)

    try:
        # æŠ‘åˆ¶ç‰¹å®šçš„UserWarning
        import warnings
        with warnings.catch_warnings():
            warnings.filterwarnings("ignore", category=UserWarning)
            warnings.filterwarnings("ignore", category=DeprecationWarning)
            torch.onnx.export(
                model, dummy_input, onnx_path, export_params=True, opset_version=12,
                do_constant_folding=True, input_names=['input'], output_names=['output_reg', 'output_cls'],
                dynamic_axes={'input': {0: 'batch_size'}, 'output_reg': {0: 'batch_size'},
                              'output_cls': {0: 'batch_size'}}
            )
    except Exception as e:
        # å³ä½¿æŠ¥é”™ä¹Ÿå¯èƒ½æ˜¯ç¯å¢ƒé—®é¢˜ï¼Œåªè¦æ–‡ä»¶ç”Ÿæˆäº†å°±ç®—æˆåŠŸ
        if not os.path.exists(onnx_path):
            return False, f"ONNXå¯¼å‡ºå¼‚å¸¸: {e}"

    return True, "æˆåŠŸ"


def parse_selection(input_str, max_len):
    """è§£æç”¨æˆ·è¾“å…¥"""
    input_str = input_str.strip().lower()
    if input_str == 'all':
        return list(range(max_len))

    selected = set()
    # æ›¿æ¢é€—å·ä¸ºæ‰€æœ‰çš„ç©ºæ ¼
    parts = input_str.replace(',', ' ').split()

    for part in parts:
        if '-' in part:
            try:
                start, end = map(int, part.split('-'))
                # ç”¨æˆ·è¾“å…¥æ˜¯1-basedï¼Œè½¬ä¸º0-basedåŒºé—´
                selected.update(range(start - 1, end))
            except ValueError:
                pass
        else:
            try:
                idx = int(part) - 1
                if 0 <= idx < max_len:
                    selected.add(idx)
            except ValueError:
                pass

    return sorted(list(selected))


def main():
    print("æ­£åœ¨æ‰«æå¯ç”¨çš„æœ€ä½³ç­–ç•¥...")
    stocks = get_available_stocks()

    if not stocks:
        print("æœªæ‰¾åˆ°ä»»ä½•å«æœ‰ best_metrics.csv çš„è‚¡ç¥¨è®°å½•ã€‚è¯·å…ˆè¿è¡Œ filter_trading_signals.pyã€‚")
        return

    while True:
        print("\n" + "=" * 40)
        print("å¯ç”¨è‚¡ç¥¨åˆ—è¡¨:")
        for i, s in enumerate(stocks):
            print(f"[{i + 1}] {s['sector']} - {s['name']}")
        print("=" * 40)

        print("è¯·è¾“å…¥æŒ‡ä»¤:")
        print("  - è¾“å…¥ 'all' : å¯¼å‡ºæ‰€æœ‰è‚¡ç¥¨")
        print("  - è¾“å…¥æ•°å­— (å¦‚ '1') : å¯¼å‡ºå•ä¸ª")
        print("  - è¾“å…¥åˆ—è¡¨ (å¦‚ '1 3 5') : å¯¼å‡ºå¤šä¸ª")
        print("  - è¾“å…¥èŒƒå›´ (å¦‚ '1-5') : å¯¼å‡ºåŒºé—´")
        print("  - è¾“å…¥ 'q' : é€€å‡ºç¨‹åº")

        choice = input("\nè¯·é€‰æ‹©: ").strip()
        if choice.lower() == 'q':
            break

        selected_indices = parse_selection(choice, len(stocks))

        if not selected_indices:
            print("âŒ æ— æ•ˆçš„è¾“å…¥ï¼Œè¯·é‡æ–°é€‰æ‹©ã€‚")
            continue

        print(f"\nğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {len(selected_indices)} ä¸ªä»»åŠ¡...\n")

        success_count = 0
        fail_count = 0
        failed_stocks = []

        start_time = time.time()

        for idx in selected_indices:
            stock = stocks[idx]
            # å¦‚æœæ˜¯æ‰¹é‡(>1ä¸ª)ï¼Œå¼€å¯quietæ¨¡å¼å‡å°‘åˆ·å±
            is_quiet = len(selected_indices) > 1

            # æ˜¾ç¤ºè¿›åº¦æ¡é£æ ¼çš„æç¤º
            print(f"[{idx + 1}/{len(stocks)}] å¤„ç†: {stock['name']} ... ", end='', flush=True)

            success, msg = export_stock(stock, quiet=is_quiet)

            if success:
                print("âœ… æˆåŠŸ")
                success_count += 1
            else:
                print(f"âŒ å¤±è´¥ ({msg})")
                fail_count += 1
                failed_stocks.append(f"{stock['name']}: {msg}")

        total_time = time.time() - start_time
        print("\n" + "-" * 30)
        print(f"ğŸ“Š å¤„ç†å®Œæˆï¼è€—æ—¶: {total_time:.2f}s")
        print(f"âœ… æˆåŠŸ: {success_count}")
        print(f"âŒ å¤±è´¥: {fail_count}")
        if failed_stocks:
            print("å¤±è´¥è¯¦æƒ…:")
            for f in failed_stocks:
                print(f"  - {f}")
        print("-" * 30)

        if len(selected_indices) == len(stocks):
            # å¦‚æœæ˜¯å…¨éƒ¨å¯¼å‡ºï¼Œé€šå¸¸è·‘å®Œä¸€æ¬¡å°±æƒ³é€€å‡ºäº†ï¼Œä½†ä¹Ÿå…è®¸ç»§ç»­
            pass


if __name__ == "__main__":
    main()