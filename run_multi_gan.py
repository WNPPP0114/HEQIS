# 文件名: run_multi_gan.py (最终版：已移除对save_scalers的调用)

import argparse
import pandas as pd
import os
import glob
import time
from utils.logger import setup_experiment_logging
from time_series_maa import MAA_time_series
import torch
import sys
from models.pretrainer import (
    visualize_reconstruction,
    visualize_feature_correlation,
    visualize_encoded_feature_correlation
)


def find_stock_files(base_dir, stock_name=None, sector=None):
    search_pattern = os.path.join(base_dir, 'train', '**', '*.csv')
    all_files = glob.glob(search_pattern, recursive=True)
    found_files = []
    if not stock_name and not sector:
        return all_files
    for f in all_files:
        path_parts = f.replace('\\', '/').split('/')
        if len(path_parts) < 3:
            continue
        file_stock_name = path_parts[-2]
        file_sector = path_parts[-3]
        if stock_name and file_stock_name == stock_name:
            found_files.append(f)
        elif sector and file_sector == sector:
            found_files.append(f)
    return found_files


def run_experiment_for_stock(args, stock_csv_path):
    path_parts = stock_csv_path.replace('\\', '/').split('/')
    stock_name = path_parts[-2]
    sector_name = path_parts[-3]

    experiment_base_dir = os.path.join(args.output_dir, sector_name, stock_name)
    stock_specific_ckpt_dir = os.path.join(experiment_base_dir, 'ckpt')
    stock_specific_output_dir = experiment_base_dir

    os.makedirs(stock_specific_output_dir, exist_ok=True)
    os.makedirs(stock_specific_ckpt_dir, exist_ok=True)

    print(f"\n{'=' * 20} 开始处理股票: {sector_name} - {stock_name} {'=' * 20}")
    print(f"数据源: {stock_csv_path}")
    print(f"统一实验目录: {stock_specific_output_dir}")
    print(f"模型保存目录: {stock_specific_ckpt_dir}")

    local_args = argparse.Namespace(**vars(args))
    local_args.output_dir = stock_specific_output_dir
    local_args.ckpt_dir = stock_specific_ckpt_dir
    local_args.train_csv_path = stock_csv_path

    gca = MAA_time_series(local_args,
                          local_args.N_pairs, local_args.batch_size, local_args.num_epochs,
                          local_args.generators, local_args.discriminators,
                          stock_specific_ckpt_dir, stock_specific_output_dir,
                          local_args.window_sizes,
                          ckpt_path=local_args.ckpt_path,
                          initial_learning_rate=local_args.lr,
                          do_distill_epochs=local_args.distill_epochs,
                          cross_finetune_epochs=local_args.cross_finetune_epochs,
                          device=local_args.device,
                          seed=local_args.random_seed)

    if 'mpd' in local_args.generators and local_args.pretrain:
        unique_mpd_window_sizes = sorted(list(set(
            ws for gen, ws in zip(local_args.generators, local_args.window_sizes) if gen == 'mpd'
        )))
        print(f"\n--- 发现需要为以下窗口大小进行预训练: {unique_mpd_window_sizes} ---")
        for ws in unique_mpd_window_sizes:
            pretrainer_ckpt_path = os.path.join(stock_specific_output_dir,
                                                f"{local_args.pretrainer_type}_encoder_ws{ws}.pt")
            if os.path.exists(pretrainer_ckpt_path):
                print(f"--- 已找到 window_size={ws} 的预训练权重 '{pretrainer_ckpt_path}'，跳过预训练。 ---")
            else:
                print(f"--- 开始为 window_size={ws} 进行预训练... ---")
                gca.run_pretraining_if_needed(
                    all_stock_files=[stock_csv_path],
                    pretrainer_ckpt_path=pretrainer_ckpt_path,
                    pretrain_epochs=local_args.pretrain_epochs,
                    specific_window_size=ws
                )
                print(f"--- window_size={ws} 的 {local_args.pretrainer_type.upper()} 预训练完成。权重已保存至 '{pretrainer_ckpt_path}'。 ---")

    full_df_path = stock_csv_path
    full_df = pd.read_csv(full_df_path, usecols=['date'])
    date_series = pd.to_datetime(full_df['date'], format='%Y%m%d')
    predict_csv_path = stock_csv_path.replace(os.path.join('train'), os.path.join('predict'))
    gca.process_data(
        train_csv_path=stock_csv_path,
        predict_csv_path=predict_csv_path,
        target_column='close',
        exclude_columns=['date', 'direction']
    )
    gca.init_dataloader()

    visualize_feature_correlation(gca)

    if 'mpd' in local_args.generators and local_args.pretrain:
        unique_mpd_window_sizes_vis = sorted(list(set(
            ws for gen, ws in zip(local_args.generators, local_args.window_sizes) if gen == 'mpd'
        )))
        for ws in unique_mpd_window_sizes_vis:
            ckpt_path_vis = os.path.join(stock_specific_output_dir, f"{local_args.pretrainer_type}_encoder_ws{ws}.pt")
            if os.path.exists(ckpt_path_vis):
                visualize_reconstruction(gca, ckpt_path_vis, local_args.pretrainer_type, target_window_size=ws)
                visualize_encoded_feature_correlation(gca, ckpt_path_vis, local_args.pretrainer_type, target_window_size=ws)

    gca.init_model(local_args.num_classes)
    logger = setup_experiment_logging(stock_specific_output_dir, vars(local_args), f"train_{stock_name}")

    results = None
    if local_args.mode == "train":
        results, best_model_state = gca.train(logger, date_series=date_series)
        if best_model_state and any(s is not None for s in best_model_state):
            print("\n--- 训练结束，保存相关产物 ---")
            gca.save_models(best_model_state)
            # gca.save_scalers()  # <-- 已移除
            gca.generate_and_save_daily_signals(best_model_state, predict_csv_path)
            print("\n--- 加载最佳模型以生成预测对比CSV ---")
            for i in range(gca.N):
                if i < len(best_model_state) and best_model_state[i] is not None:
                    if i < len(gca.generators):
                        try:
                            gca.generators[i].load_state_dict(best_model_state[i])
                        except Exception as e:
                            print(f"警告: 加载生成器 G{i + 1} 状态用于 CSV 生成失败: {e}")
                    else:
                        print(f"警告: G{i + 1} 生成器未被初始化。")
            gca.save_predictions_to_csv(date_series=date_series)
    elif local_args.mode == "pred":
        results = gca.pred(date_series=date_series)

    if results:
        master_results_file = os.path.join(args.output_dir, "master_results.csv")
        timestamp_for_log = time.strftime("%Y%m%d-%H%M%S")
        result_row = {"timestamp": timestamp_for_log, "sector": sector_name, "stock": stock_name,
                      "train_mse": results["train_mse"], "train_mae": results["train_mae"],
                      "test_mse": results["test_mse"], "test_mae": results["test_mae"]}
        df = pd.DataFrame([result_row])
        header = not os.path.exists(master_results_file)
        df.to_csv(master_results_file, mode='a', header=header, index=False)
        print(f"===== 股票 {stock_name} 处理完毕, 结果已记录到 {master_results_file} =====")
    else:
        print(f"===== 股票 {stock_name} 处理完毕, 但没有结果需要记录 =====")